import sounddevice as sd
import numpy as np
import queue
import threading
from datetime import datetime, timedelta
import noisereduce as nr
import webrtcvad
import collections
from elevenlabs import generate, play, set_api_key
import io
import soundfile as sf
import wave
import whisper

class AudioBuffer:
    def __init__(self, maxlen=10):
        self.buffer = collections.deque(maxlen=maxlen)
        
    def add(self, data):
        self.buffer.append(data)
        
    def clear(self):
        self.buffer.clear()
        
    def get_data(self):
        return np.concatenate(list(self.buffer)) if self.buffer else np.array([])

class VoiceChanger:
    def __init__(self, voice_id, api_key):
        # Initialize ElevenLabs
        set_api_key(api_key)
        self.voice_id = voice_id
        
        # Audio settings
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_duration = 0.5  # 500ms chunks for lower latency
        self.chunk_size = int(self.sample_rate * self.chunk_duration)
        
        # Audio processing
        self.vad = webrtcvad.Vad(3)  # Voice Activity Detection
        self.audio_buffer = AudioBuffer(maxlen=20)
        self.silence_threshold = 0.03
        self.min_speech_duration = 0.5  # seconds
        
        # State management
        self.last_speech_time = None
        self.is_speaking = False
        self.is_running = False
        self.audio_queue = queue.Queue()
        
        # Initialize whisper for speech-to-text (needed for ElevenLabs input)
        self.whisper_model = whisper.load_model("base")
        
    def start_recording(self):
        """Start capturing audio from the virtual audio device"""
        self.is_running = True
        
        def audio_callback(indata, frames, time, status):
            if status:
                print(f"Status: {status}")
            self.audio_queue.put(indata.copy())
        
        self.stream = sd.InputStream(
            channels=self.channels,
            samplerate=self.sample_rate,
            callback=audio_callback
        )
        self.stream.start()
        
    def stop_recording(self):
        """Stop capturing audio"""
        self.is_running = False
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
            
    def reduce_noise(self, audio_data):
        """Apply noise reduction to audio data"""
        try:
            reduced_noise = nr.reduce_noise(
                y=audio_data,
                sr=self.sample_rate,
                prop_decrease=0.95,
                n_fft=1024
            )
            return reduced_noise
        except Exception as e:
            print(f"Error in noise reduction: {e}")
            return audio_data

    def is_speech(self, audio_data):
        """Detect if audio contains speech"""
        try:
            audio_int16 = (audio_data * 32767).astype(np.int16)
            frames = frame_generator(30, audio_int16, self.sample_rate)
            return any(self.vad.is_speech(frame.tobytes(), self.sample_rate) for frame in frames)
        except Exception as e:
            print(f"Error in speech detection: {e}")
            return False

    def process_audio(self):
        """Process audio chunks and perform voice conversion"""
        while self.is_running:
            try:
                audio_chunk = self.audio_queue.get(timeout=0.1)
                
                # Apply noise reduction
                cleaned_audio = self.reduce_noise(audio_chunk.flatten())
                
                # Check for speech
                if self.is_speech(cleaned_audio):
                    self.is_speaking = True
                    self.last_speech_time = datetime.now()
                    self.audio_buffer.add(cleaned_audio)
                elif self.is_speaking:
                    # Add a small delay after speech ends
                    if (datetime.now() - self.last_speech_time) > timedelta(seconds=0.5):
                        self.is_speaking = False
                        
                        # Process accumulated audio
                        audio_data = self.audio_buffer.get_data()
                        if len(audio_data) > 0:
                            try:
                                # Convert speech to text
                                result = self.whisper_model.transcribe(audio_data)
                                text = result["text"]
                                
                                if text.strip():
                                    # Generate voice using ElevenLabs
                                    audio = generate(
                                        text=text,
                                        voice_id=self.voice_id,
                                        model="eleven_monolingual_v1"
                                    )
                                    
                                    # Convert audio to numpy array and play
                                    audio_fp = io.BytesIO(audio)
                                    data, sr = sf.read(audio_fp)
                                    sd.play(data, sr)
                                    sd.wait()
                                    
                            except Exception as e:
                                print(f"Error in voice conversion: {e}")
                            
                        self.audio_buffer.clear()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"Error processing audio: {e}")
                continue

    def run(self):
        """Start the voice changer service"""
        self.start_recording()
        
        # Start processing in a separate thread
        process_thread = threading.Thread(target=self.process_audio)
        process_thread.start()
        
        try:
            while self.is_running:
                pass
        except KeyboardInterrupt:
            self.stop_recording()
            process_thread.join()

def frame_generator(frame_duration_ms, audio, sample_rate):
    """Generate audio frames from PCM audio data"""
    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)
    offset = 0
    while offset + n < len(audio):
        yield audio[offset:offset + n]
        offset += n
